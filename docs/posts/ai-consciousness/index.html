<!doctype html>
<html lang="en" dir="auto">
    <head>
          <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Human and AI Consciousness (In progress)</title>


<meta name="keywords" content="programming, AI, haskell, health">



<meta name="description" content="Staying open-minded about the chances">





<link rel="canonical" href="https:&#x2F;&#x2F;blog.greghale.io&#x2F;posts&#x2F;ai-consciousness&#x2F;">


<link rel="stylesheet" href="https://blog.greghale.io/css/includes/scroll-bar.css">
<link rel="stylesheet" href="https://blog.greghale.io/css/styles.css">
<link rel="stylesheet" href="https://blog.greghale.io/css/override.css">







<link rel="alternate" type="application/rss+xml" title="RSS" href="https://blog.greghale.io/rss.xml">



<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }
    </style>
    
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
    
</noscript>






 
<link rel="stylesheet" href="https://blog.greghale.io/css/custom.css" />
 
    </head>
    <body
        class=""
        id="top"
    >
         
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https:&#x2F;&#x2F;blog.greghale.io" accesskey="h" title="Greg Hale&#x27;s Blog (Alt + H)">
                Greg Hale&#x27;s Blog
            </a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch">
                    <li></li>
                </ul>
            </div>
        </div>
        
        <ul id="menu">
            
            
            
            <li>
                <a href="https:&#x2F;&#x2F;blog.greghale.io&#x2F;posts" title="Posts" >
                    <span>Posts</span>
                    
                </a>
            </li>
            
            
            
            <li>
                <a href="https:&#x2F;&#x2F;blog.greghale.io&#x2F;tags" title="Tags" >
                    <span>Tags</span>
                    
                </a>
            </li>
            
            
            
            <li>
                <a href="https:&#x2F;&#x2F;blog.greghale.io&#x2F;rss.xml" title="RSS" >
                    <span>RSS</span>
                    
                </a>
            </li>
            
        </ul>
        
    </nav>
</header>
 
        <main class="main">
            
<article class="post-single">
    <header class="post-header">
        <div class="breadcrumbs">
            <a href="https:&#x2F;&#x2F;blog.greghale.io">Home</a>&nbsp;»&nbsp;
            <a href="https://blog.greghale.io/posts/">Posts</a
            >&nbsp;»&nbsp;
            <a href="https:&#x2F;&#x2F;blog.greghale.io&#x2F;posts&#x2F;ai-consciousness&#x2F;">Human and AI Consciousness (In progress)</a>
        </div>
        <h1 class="post-title">Human and AI Consciousness (In progress)</h1>
        
        <div class="post-description">Staying open-minded about the chances</div>
        
        <div class="post-meta">












<span title="2025-10-24 00:00:00 +0000">October 24, 2025</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;
</div>
    </header>
    
    <div class="post-content"><p>Are LLM's conscious? There's a lot of chatter about it on LinkedIn,
and I'm occasionally surprised to hear that the idea of a conscious
LLM is absurd because LLMs are mechanistically nothing like the
the consciousness of human brains. Because, well, neuroscience has
no idea how consciousness works! The front-running theory of
consciousness for the past two decades has been Gulio Tononi's
Integrated Information Theory, and although it doesn't have any
major competitors, it's not universally accepted. Nowhere close.</p>
<p>If we don't have a unified theory of consciousness, what do we have?
A large number of experiments that tell us discrete facts <em>about</em>
consciousness. Many of them deviate from the intuitions we have
about consciousness from our own introspection.</p>
<p>In this post I'd like to give you a bit of what neuroscience knows
about consciousness, and to convince you that the right attitude
to have about consciousness in LLMs is cautious agnosticism.</p>
<h2 id="warmup-brain-transplants">Warmup - Brain Transplants</h2>
<p>Let's warm up your own consciousness with a thought experiment.
You've worked out the formula for cold fusion! Driving to the lab
in your excitement to share the results, you crash into another car.</p>
<p>You and your victim are in bad shape. The doctors tell you they're
all set up to do the world's first brain transplant. One body and one brain are going to go home tonight, the others unfortunately won't. They just need to know one thing - would you rather be the
brain donor or the brain recipient?</p>
<p>Putting aside altruism for a moment, what's the selfish choice?
It's to be the donor, of course. "You" are the brain, more than
the rest of the body, so it's more appropriate to think of this
operation as a body-and-face transplant, rather than a brain
transplant, since your identity certainly moves with your brain.
If you took the other choice and accepted a brain donation,
contratulations, your wonderful body lives on, but "you" aren't
here to appreciate that fact. Oh, and that cold fusion formula
is gone, too.</p>
<h2 id="warmup-fragmented-consciousness-constructed-continuity">Warmup - Fragmented Consciousness, Constructed Continuity</h2>
<p>One framework for consciousness suggested by psychophysics
experiments is that consciousness is discontinuous.
Although you experience yourself as existing smoothly through
every point in time that you are awake, your true conscious
experiences are deceptively fragmented. Visual illusions,
transcratial magnetic stimulation studies and brain
wave recordings suggest that we experience new percpepts 4-20
times a second. Each percept may embed the sense of motion
of objecects in your visual scene, but your conscious "frame rate"
is much lower (2-5Hz) than the frame rate available to the sensors
in your eyes (~200Hz). But the sense of continuity of conscious
experience was reconstcuted by your brain after the fact.</p>
<p><img src="/images/2025-10-24-chunked-consciousness.png" alt="The two-stage model" /></p>
<p>This diagram helps to illustrate the idea. (a) a purple ball moves
continuously up against a screen. (b) The retina encodes this as
a collection of pixel intensities along with information about
velocity at a high "frame rate". Each "frame" contains a pixelated
image and a motion vector. (c) and (d) after some analysis in the
brainstem and thalamus, the visual signals are split to the dorsal
stream, which represents the stimulus' position and motion vectors
at a high "frame rate", and the ventral stream, which encodes
object color and identity at a lower frame rate. (e) these signals
converge in the frontal cortex where the features are integrated
into a conscious percept at a low frame rate. Here, each frame
contains both the object identity and a motion signal. (top) the
wall-clock time of these represented percepts are low in "frame rate",
but (bottom) the motion vectors present at each instance of
a conscious percept result in the sensation of perception existing
continuously in time and tracking the object smoothly. But this
sensation just is a reconstruction - the true instances of
perception - the moments at which you are conscious of the
stimulus - are discontinuous.</p>
<p>If that's hard to swallow, notice that post-hoc reconstruction
is extremely common. It's easy to verify an analogous form of
reconstruction in our visual system. There are two ways to
do it, let's try both.</p>
<p>First, observe your surroundings and get a sense of how clearly
you see the room you're in. How many doors can you see? How many
people, books? How many open windows and roughly how many browser
tabs are visible on the screen? These are easy questions to answer.
Now, pick a single object, and force your eyes
to stay glued to it for 20 seconds. While locked on to that one
object, how much detail is still available to you? Pick one
word in this paragraph and stare at it - without moving your eyes
try to identify the two words to its left and right, or the
words from two lines above or below. What I hope you experience
from this exercise is the difference between
intuition of a full, high-resolution, camera-like visual field,
and reality for our vision - more like a pinhole camera that swivels
its high-accuracy part around while your brain integrates the information
to construct a full picture for you.</p>
<p>Second, there is one part of each of your retinas that is fully blind.
Because of your reconstructed visual field, you don't experience this
as a perceptual hole - you experience a perfectly valid visual field.
But by closing one eye and fixing it on the cross below, then moving
the slider, you can place the blinking dot into your blind spot, and
it will appear to you that the pane only contains the fixation cross,
no blinking lighth and no "hole".</p>
<div id="blind-spot-finder"></div>
<script src="/js/blind-spot-finder.js"></script>
<p>In summary, your brain constructs a full, seamless picture for you
from sparse sensory information. The seamless picture suggests a
natural model of how pereption works: sensory organs faithfully
transmit a full picture of the world deep into your brain for
conscious perception to "watch". But that model is inaccurate for
vision - the sensors are sparse and the picture is not received,
but constructed.</p>
<p>The two-stage model of consciousness proposes a similar
deconstruction of natural models of consciousness. We perceive
that we are conscious at all (waking) points in time, but
the continuity is a perceptual reconstruction. You are only truly
conscious a few times per second, and each of those chunks carries
the mere feeling of continuity.</p>
<h2 id="soul-transplants-and-identity">Soul Transplants and Identity</h2>
<p>Even if consciosness exists in discrete chunks, what can we
say about how those chunks relate to one another? Another of
our core native beliefs about consciousness is that it's
"continuous" in the sense of extending through time - it's the
"same" conscious being that exists from moment to moment, maybe
not "continuously" in sense of being not-chunked, but at least
persistent and linked from chunk to chunk.</p>
<p>Let's scrutinize this view though, with a thought experiment.
Assume the existence of a soul. Your soul is your consciousness,
and it is the thing links together your chunks of consciousness
into a narrative sequence. However, in this hypothetical, we are
still neuroscientists and we still recognize that physiological
things like synaptic strength and neuron dynamics are the
physical basis of both long-term, short-term and perceptual memory.</p>
<p>Now imagine that conscious soul could hop between bodies - trade
places for a moment with another soul and see through another's
eyes. What would this feel like?</p>
<p>The answer depends on parameter that I haven't specified, and which
you might not have questioned: are physiological processes the only
form or memory, or does the soul posess its own memory system that
is somehow either complementary or redundant with physiological
memory?</p>
<p>If all memory is physical, but there is a soul that experiences,
swapping souls would feel exactly like: <em>nothing</em>. When your
soul hops into a new body, it also hops into the existing <em>memories</em>,
and when your soul returns to your body, it once again encounters
only your body's memories, carrying none of the other body's memories
back with it.</p>
<p>In this magical trip to another brain and back, there wouldn't a
single trace.</p>
<p>Now, if your soul somehow does have its own memory system, which
is somehow either complementary or redundant with the physical
memory systems, you would remember.</p>
<p>The point of this thought experiment isn't to imagine souls or to
work out whether they have memory. It's to point out how fragmented
our consciousness is, and how differently it exists, compared to
the two forms of continuity that we tacitly assume to be the
essential aspects of consciousness.</p>
<p>When you fully internalize this model, you may feel that you
have no more moral obligation to yourself than you do to any
other human. The fragment of consciousness is no the same
consciousness as the frament that exists right now. It's a new
fragment that exists in the same physical body and has access
to the same set of memories.</p>
<h2 id="a-von-neuman-model-of-consciousness">A Von-Neuman model of consciousness</h2>
<p>In this state of accepting consciousness as an essentially
discontinuous thing, only <em>appearing</em> smooth due to sensory
reconstruction and continuous moment-to-moment because of physical
memory, we can draw an analogy between human consciousness and
the von Neuman model of computation.</p>
<p>Consciousnes is bracketed into clock cycles. On every cycle,
it "starts cold" in the sense of having no non-physical memory,
rather it is dropped into a preexisting mode of long-term and
short-term memories. Just like your hypothetical soul inserted
into a new body experiences no shock of finding itself in a new
body. Consciousness is the logic processor in the CPU. Each clock
cycle it processes the instructions and manipulates the memory
in its registers and its RAM. The memory system is completely
separate from it and is the only thing providing continuity from
cycle to cycle.</p>
<p>Or for a different metaphor with the same flavor, consciousness
is the agentic LLM API. Every request you make encounteres a
fresh system. Continuity is supplied through the API request via
context engineering. It makes no difference at all if your first
agentic API request goes to a server farm in us-east-1 and the
following one goes to a server farm in jp-1. Neither the model
nor you can tell the difference.</p>
</div>
    <footer class="post-footer">
          


<nav class="paginav">
    
    <a class="prev" href="https:&#x2F;&#x2F;blog.greghale.io&#x2F;posts&#x2F;jj-for-vibe-coding&#x2F;">
        <span class="title">« Prev</span>
        <br>
        <span>jj loves vibe coding</span>
    </a>
    
    
</nav>

 
    </footer>
</article>

        </main>
         <footer class="footer">
    
    <span>&copy; 2025 <a href="https:&#x2F;&#x2F;blog.greghale.io"></a></span>
    
    <span>
        Powered by
        <a href="https://www.getzola.org/" rel="noopener noreferrer" target="_blank">Zola</a> &
        <a href="https://github.com/cydave/zola-theme-papermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>


<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>


<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>


<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>



<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>


<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';
        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                var content = codeblock.textContent;
                if(codeblock.firstChild.tagName == 'TABLE') {
                    content = Array(...codeblock.firstChild.getElementsByTagName('span')).map((span) => { return span.textContent; }).join('');
                }
                navigator.clipboard.writeText(content);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            // td containing LineNos
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            // table containing LineNos and code
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            // code blocks not having highlight as parent class
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>


 
    </body>
</html>
